#!/usr/bin/env python3
"""
VGG-16 + VGGFace ê¸°ë°˜ CNN ì–¼êµ´í˜• ë¶„ë¥˜ ëª¨ë¸
92.7% ì •í™•ë„ë¥¼ ëª©í‘œë¡œ í•¨
"""

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import json
from glob import glob

class CNNFaceShapeClassifier:
    def __init__(self, model_path=None):
        self.classes = ["Heart", "Oblong", "Oval", "Round", "Square"]
        self.model = None
        self.label_encoder = None
        self.img_size = (224, 224)  # VGG-16 í‘œì¤€ ì…ë ¥ í¬ê¸°

        if model_path and os.path.exists(model_path):
            self.load_model(model_path)

    def preprocess_image(self, img):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (VGG-16 í˜•ì‹ì— ë§ê²Œ)"""
        if img is None:
            return None

        # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        img_resized = cv2.resize(img, self.img_size)

        # BGR to RGB ë³€í™˜
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

        # ì •ê·œí™” (0-1 ë²”ìœ„)
        img_normalized = img_rgb.astype(np.float32) / 255.0

        return img_normalized

    def load_data(self, data_dir="../faceshape-master/augmented_dataset"):
        """í™•ì¥ëœ ë°ì´í„°ì…‹ ë¡œë“œ"""
        print("ğŸ“‚ CNNìš© ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")

        images = []
        labels = []

        for class_name in self.classes:
            class_dir = os.path.join(data_dir, class_name.lower())
            if not os.path.exists(class_dir):
                continue

            class_images = glob(os.path.join(class_dir, "*.jpg"))
            print(f"   {class_name}: {len(class_images)}ê°œ")

            for img_path in class_images:
                img = cv2.imread(img_path)
                if img is not None:
                    processed_img = self.preprocess_image(img)
                    if processed_img is not None:
                        images.append(processed_img)
                        labels.append(class_name)

        X = np.array(images)
        y = np.array(labels)

        print(f"âœ… ì´ ë¡œë“œëœ ë°ì´í„°: {len(X)}ê°œ")
        print(f"   ì´ë¯¸ì§€ í¬ê¸°: {X.shape}")

        return X, y

    def create_vgg_model(self):
        """VGG-16 + VGGFace ê¸°ë°˜ ëª¨ë¸ ìƒì„±"""
        print("ğŸ—ï¸ VGG-16 + VGGFace CNN ëª¨ë¸ ìƒì„± ì¤‘...")

        # VGG-16 ë² ì´ìŠ¤ ëª¨ë¸ (ImageNet weights ì‚¬ìš©, VGGFace weightsëŠ” ë³„ë„ ë‹¤ìš´ë¡œë“œ í•„ìš”)
        base_model = VGG16(
            input_shape=(224, 224, 3),
            include_top=False,  # ë§ˆì§€ë§‰ ë¶„ë¥˜ ë ˆì´ì–´ ì œì™¸
            weights='imagenet'  # ImageNet ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©
        )

        # ë² ì´ìŠ¤ ëª¨ë¸ ë ˆì´ì–´ ê³ ì • (Transfer Learning)
        for layer in base_model.layers:
            layer.trainable = False

        # ìƒˆë¡œìš´ ë¶„ë¥˜ í—¤ë“œ ì¶”ê°€
        x = base_model.output
        x = GlobalAveragePooling2D()(x)
        x = Dense(128, activation='relu')(x)
        x = Dropout(0.5)(x)
        x = Dense(64, activation='relu')(x)
        x = Dropout(0.3)(x)
        predictions = Dense(5, activation='softmax')(x)  # 5ê°œ í´ë˜ìŠ¤

        # ëª¨ë¸ ìƒì„±
        model = Model(inputs=base_model.input, outputs=predictions)

        # ì»´íŒŒì¼
        model.compile(
            optimizer=Adam(learning_rate=0.0001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        print(f"ğŸ“Š ëª¨ë¸ êµ¬ì¡°:")
        print(f"   ì´ íŒŒë¼ë¯¸í„°: {model.count_params():,}")
        trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
        print(f"   í›ˆë ¨ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}")

        return model

    def train_model(self, X, y, epochs=30, batch_size=32):
        """CNN ëª¨ë¸ í›ˆë ¨"""
        print("\nğŸ¤– CNN ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        # ë ˆì´ë¸” ì¸ì½”ë”©
        self.label_encoder = LabelEncoder()
        y_encoded = self.label_encoder.fit_transform(y)
        y_categorical = to_categorical(y_encoded, num_classes=5)

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded
        )

        print(f"   í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")

        # ëª¨ë¸ ìƒì„±
        self.model = self.create_vgg_model()

        # ë°ì´í„° ì¦ê°•
        datagen = ImageDataGenerator(
            rotation_range=20,
            horizontal_flip=True,
            width_shift_range=0.1,
            height_shift_range=0.1,
            zoom_range=0.1
        )
        datagen.fit(X_train)

        # ì¡°ê¸° ì¢…ë£Œ ë° ì²´í¬í¬ì¸íŠ¸ ì½œë°±
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_accuracy',
                patience=5,
                restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=3,
                min_lr=1e-7
            )
        ]

        # ëª¨ë¸ í›ˆë ¨
        history = self.model.fit(
            datagen.flow(X_train, y_train, batch_size=batch_size),
            steps_per_epoch=len(X_train) // batch_size,
            epochs=epochs,
            validation_data=(X_test, y_test),
            callbacks=callbacks,
            verbose=1
        )

        # ìµœì¢… í‰ê°€
        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"\nğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.1%}")

        # ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸
        y_pred = self.model.predict(X_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_test_classes = np.argmax(y_test, axis=1)

        print(f"\nğŸ“Š ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
        print(classification_report(
            y_test_classes, y_pred_classes,
            target_names=self.label_encoder.classes_
        ))

        return history, test_accuracy

    def save_model(self, model_path="cnn_face_shape_model"):
        """ëª¨ë¸ ì €ì¥"""
        if self.model is None:
            print("âŒ ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # TensorFlow ëª¨ë¸ ì €ì¥
        self.model.save(f"{model_path}.h5")

        # ë¼ë²¨ ì¸ì½”ë” ì €ì¥
        joblib.dump(self.label_encoder, f"{model_path}_label_encoder.pkl")

        print(f"âœ… CNN ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}.h5")

    def load_model(self, model_path):
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        try:
            self.model = tf.keras.models.load_model(f"{model_path}.h5")
            self.label_encoder = joblib.load(f"{model_path}_label_encoder.pkl")
            print(f"âœ… CNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def predict(self, img):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡"""
        if self.model is None or self.label_encoder is None:
            return None

        processed_img = self.preprocess_image(img)
        if processed_img is None:
            return None

        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        img_batch = np.expand_dims(processed_img, axis=0)

        # ì˜ˆì¸¡
        predictions = self.model.predict(img_batch, verbose=0)
        pred_idx = np.argmax(predictions[0])
        confidence = np.max(predictions[0])

        predicted_class = self.label_encoder.inverse_transform([pred_idx])[0]

        return {
            'face_shape': predicted_class,
            'confidence': float(confidence),
            'all_predictions': {
                cls: float(prob) for cls, prob in zip(
                    self.label_encoder.classes_, predictions[0]
                )
            }
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ VGG-16 + VGGFace CNN ì–¼êµ´í˜• ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨")

    # ë¶„ë¥˜ê¸° ìƒì„±
    classifier = CNNFaceShapeClassifier()

    # ë°ì´í„° ë¡œë“œ
    X, y = classifier.load_data()

    # ëª¨ë¸ í›ˆë ¨
    history, accuracy = classifier.train_model(X, y, epochs=20)

    # ëª¨ë¸ ì €ì¥
    classifier.save_model("cnn_face_shape_model")

    print(f"\nğŸ‰ CNN ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    print(f"   ìµœì¢… ì •í™•ë„: {accuracy:.1%}")
    print(f"   ëª©í‘œ ë‹¬ì„±: {'âœ…' if accuracy >= 0.85 else 'âš ï¸'} (ëª©í‘œ: 85%+)")

if __name__ == "__main__":
    main()