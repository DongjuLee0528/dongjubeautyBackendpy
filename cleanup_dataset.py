#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œ ì´ë¯¸ì§€ ì œê±°
- ì •ë¦¬ëœ ë°ì´í„°ì…‹ì„ ìƒˆ í´ë”ì— ë³µì‚¬
"""

import os
import json
import shutil
from pathlib import Path

def cleanup_dataset():
    """ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ì…‹ ì •ë¦¬"""

    # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
    with open('data_quality_report.json', 'r', encoding='utf-8') as f:
        results = json.load(f)

    print("ğŸ§¹ ë°ì´í„°ì…‹ ì •ë¦¬ ì‹œì‘...")

    # ì›ë³¸ ë°ì´í„°ì…‹ ê²½ë¡œ
    original_dir = "../faceshape-master/published_dataset"
    cleaned_dir = "../faceshape-master/cleaned_dataset"

    # ì •ë¦¬ëœ ë°ì´í„°ì…‹ í´ë” ìƒì„±
    if os.path.exists(cleaned_dir):
        shutil.rmtree(cleaned_dir)
    os.makedirs(cleaned_dir)

    # í´ë˜ìŠ¤ë³„ í´ë” ìƒì„±
    classes = ["heart", "oblong", "oval", "round", "square"]
    for cls in classes:
        os.makedirs(os.path.join(cleaned_dir, cls))

    # ì œê±°í•  íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    files_to_remove = set()

    # 1. ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨ ì´ë¯¸ì§€
    for item in results['face_detection']['failed_detection']:
        files_to_remove.add(item['path'])

    # 2. ë‹¤ì¤‘ ì–¼êµ´ ì´ë¯¸ì§€ (2ê°œ ì´ìƒ)
    for item in results['face_detection']['multiple_faces']:
        files_to_remove.add(item['path'])

    # 3. ì €í’ˆì§ˆ ì´ë¯¸ì§€ (ë¸”ëŸ¬ ì ìˆ˜ê°€ ë§¤ìš° ë‚®ì€ ê²ƒë§Œ)
    for item in results['image_quality']['low_quality']:
        if item['reason'] == 'Too blurry' and item.get('blur_score', 100) < 50:
            files_to_remove.add(item['path'])

    # 4. ì¤‘ë³µ ì´ë¯¸ì§€ (ê° ê·¸ë£¹ì—ì„œ ì²« ë²ˆì§¸ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì œê±°)
    for group in results['duplicates']:
        for i in range(1, len(group)):  # ì²« ë²ˆì§¸ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ì œê±°
            files_to_remove.add(group[i]['path'])

    print(f"ğŸ“ ì œê±°í•  íŒŒì¼: {len(files_to_remove)}ê°œ")

    # íŒŒì¼ ë³µì‚¬ (ë¬¸ì œ íŒŒì¼ ì œì™¸)
    copied_counts = {cls: 0 for cls in classes}
    total_copied = 0

    for cls in classes:
        original_class_dir = os.path.join(original_dir, cls)
        cleaned_class_dir = os.path.join(cleaned_dir, cls)

        if not os.path.exists(original_class_dir):
            continue

        for filename in os.listdir(original_class_dir):
            original_path = os.path.join(original_class_dir, filename)
            relative_path = os.path.join("..", "faceshape-master", "published_dataset", cls, filename)

            # ë¬¸ì œ íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ë³µì‚¬
            if relative_path not in files_to_remove and os.path.isfile(original_path):
                cleaned_path = os.path.join(cleaned_class_dir, filename)
                shutil.copy2(original_path, cleaned_path)
                copied_counts[cls] += 1
                total_copied += 1

    print(f"âœ… ì •ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ì •ë¦¬ ê²°ê³¼:")
    print(f"   ì›ë³¸: 500ê°œ â†’ ì •ë¦¬ëœ ë°ì´í„°ì…‹: {total_copied}ê°œ")
    print(f"   ì œê±°ëœ ì´ë¯¸ì§€: {500 - total_copied}ê°œ")
    print(f"   í´ë˜ìŠ¤ë³„ ë¶„í¬:")

    for cls in classes:
        print(f"     {cls}: {copied_counts[cls]}ê°œ")

    # ê· í˜•ë„ ì²´í¬
    min_count = min(copied_counts.values())
    max_count = max(copied_counts.values())
    balance_ratio = min_count / max_count if max_count > 0 else 0

    print(f"   ê· í˜•ë„: {balance_ratio:.2f} ({'âœ… ê· í˜•' if balance_ratio > 0.8 else 'âš ï¸ ë¶ˆê· í˜•'})")

    print(f"\nğŸ’¾ ì •ë¦¬ëœ ë°ì´í„°ì…‹ ì €ì¥ ìœ„ì¹˜: {cleaned_dir}")

    return cleaned_dir, copied_counts

if __name__ == "__main__":
    cleanup_dataset()